동적 프로그래밍을 사용하는 첫 번째 예제 문제는 강철 막대의 어떤 부분을 자를지 결정하는 간단한 문제입니다. 어떤 회사가 긴 강철 막대를 산 뒤, 짧은 막대로 잘라서 판매하는 상황을 가정하겠습니다. 자르는 것에는 비용이 들지 않을 때, 회사는 막대를 어떻게 잘라야 이익을 최대로 얻을 수 있는지 알고 싶어합니다.

먼저 자연수 $i = 1, 2, \dots$에 대해, $p_i$를 길이 $i$ 인 막대의 가격으로 정의합니다. 막대 길이는 항상 정수입니다.

*막대 자르기 문제*는 다음과 같습니다. 길이 $n$짜리 막대와 $i = 1, 2, \dots, n$에 대해 막대 가격 $p_i$ 가 주어졌을 때, 막대를 자르고 팔아서 얻을 수 있는 최대 수익 $r_n$을 구해야 합니다. 여기서 길이 $n$ 짜리 막대의 가격 $p_n$은 충분히 크고, 최적해는 한 번도 자르지 않은 경우가 될 수도 있습니다.

예를 들어, 아래와 같이 길이에 대한 막대의 가격이 주어졌을 때, 길이 $4$인 막대를 길이 $2$인 막대 2개로 잘랐을 때의 수익은 $10$이고, 이것이 길이 $4$인 막대에 대해서는 최대 수익입니다.

| 길이 $i$   | 1   | 2   | 3   | 4   | 5   | 6   | 7   | 8   | 9   | 10  |
| -------- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 가격 $p_i$ | 1   | 5   | 8   | 9   | 10  | 17  | 17  | 20  | 24  | 30  |
길이 $n$인 막대기를 자르는 경우의 수는 총 $2^{n - 1}$ 가지입니다.[^1] 막대기를 자르는 경우를 보편적인 덧셈을 이용해서 표현할 것입니다. 예를 들어 길이 $7$인 막대기를 길이 $2$ 짜리 막대 2개, 길이 $3$ 짜리 막대 1개로 나누는 경우를 $7 = 2 + 2 + 3$으로 표현하는 식입니다. $1\le k\le n$ 에 대해,  $k$개의 막대로 자르는 경우를 다음과 같이 쓸 수 있습니다:
$$n = i_1 + i_2 + \cdots i_k.$$
그리고 위의 경우에 대응되는 수익은 다음과 같이 쓸 수 있습니다:
$$r_n = p_{i_1} + p_{i_2} + \cdots + p_{i_k}.$$
위의 테이블에서, $1\le i \le n$에 대해, $r_i$ 값은 다음과 같이 계산될 수 있습니다.
- $r_1 = 1$ : $1 = 1$ (자르지 않는 경우)
- $r_2 = 5$ : $2 = 2$ (자르지 않는 경우)
- $r_3 = 8$ : $3 = 3$ (자르지 않는 경우)
- $r_4 = 10$ : $4 = 2 + 2$
- $r_5 = 13$ : $5 = 2 + 3$
- $r_6 = 17$ : $6 = 6$ (자르지 않는 경우)
- $r_7 = 18$ : $7 = 1 + 6$ 또는 $7 = 2 + 2 + 3$
- $r_8 = 22$ : $8 = 2 + 6$
- $r_9 = 25$ : $9 = 3 + 6$
- $r_{10} = 30$ : $10 = 10$ (자르지 않는 경우)

더 일반적으로, $r_n$을 더 짧은 막대의 최적 수익으로 구성할 수 있습니다:
$$r_n = \max(p_n, r_1 + r_{n - 1}, r_2 + r_{n - 2}, \dots, r_{n - 1} + r_1).$$
위의 식에서 최댓값의 후보 중 $p_n$은 길이 $n$인 막대를 자르지 않고 파는 경우에 해당합니다. 나머지 $n - 1$ 개의 후보들은 같은 조건에 대해 길이 $i$ 인 막대의 최적 수익과 길이 $n - i$ 인 막대의 최적 수익을 합한 값입니다. 이 값들 중 최댓값을 구할 때는 $1\le i< n$에 대해 어떤 $i$ 가 최적의 수익을 얻을 수 있는지 알 수 없기 때문에, 위와 같이 모든 $i$ 에 대해 고려해야 합니다. 

위의 식을 보면 원래 풀고자 했던 크기 $n$에 대한 문제를 풀기 위해, 같은 형태의 더 작은 문제, 즉 더 작은 크기에 대한 문제를 풀어야 합니다. 한 번 자르면 두 조각을 막대 자르기 문제의 독립적인 대상으로 고려할 수 있습니다. 전체 최적해는 두 개의 관련된 하위 문제에 대한 최적해를 포함하며, 이 두 부분 각각에서의 수익을 최대화합니다. 막대 자르기 문제는 *최적 부분 구조*[^optimal substructure]를 가진다고 말합니다. 즉, 문제에 대한 최적해는 독립적으로 해결할 수 있는 관련 하위 문제에 대한 최적해를 포함합니다.

좀 더 간단한, 재귀적 구조를 이용해서 막대 자르기 문제를 접근할 수 있습니다. 먼저 가장 왼쪽에 있는 막대 조각의 길이가 $i$ 인 경우를 생각합니다. 남은 막대의 길이는 $n - i$ 인데, 이 길이로 얻을 수 있는 최적해를 길이 $i$ 인 막대의 가격에 더하는 모든 경우를 생각하면 구하고자 하는 최적해  $r_n$을 구할 수 있습니다. 이것을 식으로 표현하면 다음과 같습니다.
$$r_n = \max_{1\le i\le n}(p_i + r_{n - i}).$$
여기서 $r_0 = 0$으로 가정합니다. 이 식에서는 원래 문제의 최적해를 구하기 위해 (두 개가 아닌) 하나의 하위 문제에 대한 최적해만 필요합니다.
###### 재귀적 하향식(top-down) 구현
아래의 의사 코드는 위의 (두 번째) 식을 그대로 구현한 것입니다.
```pseudo
function Cut-Rod(p, n):
	if n == 0 // 초기값
		return 0
	q = - ∞
	for i = 1 to n // 위의 수식 구현
		q = max(q, p[i] + Cut-Rod(p, n - i))
	return q
```

`Cut-Rod()` 함수는 가격 배열 `p`와 막대의 길이 `n`이 입력으로 주어지면 최적해를 계산해서 반환합니다. 이것을 실제로 구현해서 실행하면 적당히 큰 입력에 대해서 적지 않은 시간이 걸립니다. `n`이 40 정도만 되어도 몇 분에서 한 시간까지 걸릴 수 있습니다. 이것은 `n`이 1 커질 때마다 대략 두 배의 시간이 더 걸리기 때문입니다.

좀 더 자세히 살펴보면, `Cut-Rod()` 함수는 같은 매개변수 값에 대해 재귀적으로 호출되고, 같은 하위 문제를 반복해서 해결하게 됩니다. 예를 들어, `Cut-Rod(p, 3)`은 `Cut-Rod(p, 0)`, `Cut-Rod(p, 1)`, `Cut-Rod(p, 2)`를 호출하고, `Cut-Rod(p, 2)`는 `Cut-Rod(p, 0)`, `Cut-Rod(p, 1)`을 호출하는 식입니다. 이 과정이 재귀적으로 반복되면 수행되는 작업의 양은 주어진 `n` 값에 따라 폭발적으로 증가합니다.

`Cut-Rod()` 함수의 구체적인 실행 시간을 분석해보겠습니다. $T(n)$을 `Cut-Rod()` 함수의 두 번째 매개 변수가 `n`일 때의 `Cut-Rod()` 함수의 총 호출 횟수라고 하겠습니다. 먼저 $T(0) = 1$ 입니다. 그리고 `Cut-Rod(p, n)`은 $1\le i\le n$에 대해 `Cut-Rod(p, n - i)`를 호출하기 때문에, 다음과 같은 $T(n)$에 대한 식을 얻을 수 있습니다:
$$T(n) = 1 + \sum_{j = 0}^{n - 1} T(j).$$
이 식으로부터 $T(n) = 2^n$임을 증명할 수 있습니다(증명은 어렵지 않습니다.). 즉, `Cut-Rod()` 함수의 실행 시간은 `n`의 지수 함수입니다.

`Cut-Rod()` 함수는 전형적인 백트래킹 방식으로 구현됩니다. 길이 $n$인 막대를 자르는 모든 경우를 확인하기 때문에 실행 시간이 지수 함수인 것입니다.
###### 동적 프로그래밍을 사용해서 최적의 방법으로 막대 자르기
동적 프로그래밍을 사용해서 `Cut-Rod()` 함수를 효율적으로 수정해보겠습니다.

위의 의사 코드에서는 함수가 재귀적으로 작동하기 때문에 같은 하위 문제를 반복적으로 해결한다는 것이 문제였습니다. 한 번 해결된 하위 문제의 해를 저장하는 것으로, 각각의 하위 문제가 한 번만 해결되도록 수정하고, 만약 이미 계산된 하위 문제를 해결해야 한다면 저장된 값을 사용하는 방식으로 로직을 만들 것입니다. 동적 프로그래밍은 계산 시간을 줄이기 위해 추가적인 메모리를 사용합니다; 이것은 *타임 메모리 트레이드오프*[^time-memory trade-off]의 예로 볼 수 있습니다. 실제로 이렇게 값을 저장해서 사용하는 것은 지수 함수의 실행 시간을 다항식 함수 정도로 바꿔줍니다. 동적 프로그래밍 접근법은 관련된 서로 다른 하위 문제의 수가 입력 크기에 대해 다항식으로 계산되고, 각 하위 문제를 다항식 시간 내에 해결할 수 있을 때 다항식 시간 내에 실행됩니다.

동적 프로그래밍 접근법을 구현하는 방식은 동치인 두 가지 방법이 있습니다.
- 메모를 이용한 하향식 동적 프로그래밍
  이 접근 방식에서는 자연스러운 방식으로 절차를 재귀적으로 작성하지만 각 하위 문제의 결과를 저장하도록 수정합니다(일반적으로 배열 또는 해시 테이블). 각 절차는 먼저 계산해야 할 하위 문제가 이미 계산된 것인지 확인합니다. 만약 그렇다면 저장된 값을 사용하고, 그렇지 않으면 계산을 수행합니다. 이것을 '재귀적 절차가 *메모되었다*'고 말합니다.
- 상향식 동적 프로그래밍
  이 접근 방식은 하위 문제의 '크기'에 대한 자연스러운 개념에 의존합니다. 여기서 특정 하위 문제를 해결하는 것은 더 '작은' 하위 문제들을 해결하는 것에만 의존한다는 의미입니다. 다시 말하면, 하위 문제를 크기 순서로 정렬한 뒤, '작은' 하위 문제부터 순서대로 해결해 나갑니다. 특정 하위 문제를 해결할 때, 그것보다 작은 하위 문제는 모두 해결했기 때문에, 기존에 저장된 해를 이용해서 현재의 하위 문제를 해결합니다. 각각의 하위 문제는 한 번만 해결됩니다.

이 두 가지 접근 방식은 비정상적인 상황(예: 하향식 접근 방식이 실제로 모든 가능한 하위 문제를 재귀적으로 탐색하지 않는 경우)을 제외하고는 동일한 점근적 실행 시간을 갖는 알고리즘을 만들어냅니다. 상향식 접근 방식은 절차의 호출에 대한 오버헤드가 적어서 종종 더 좋은 상수 인수를 가집니다.

다음은 메모를 이용한 하향식 동적 프로그래밍 방식을 적용한 의사 코드입니다:
```pseudo
Memoized-Cut-Rod(p, n)
	let r[0 .. n] be a new array // 메모 배열
	for i = 0 to n
		r[i] = - ∞ // 메모 배열 초기화
	return Memoized-Cut-Rod-Aux(p, n, r)

Memoized-Cut-Rod-Aux(p, n, r)
	if r[n] >= 0 // 이미 계산된 하위 문제인지 확인
		return r[n]
	if n == 0 // 초기값
		q = 0
	else q = - ∞
		for i = 1 to n // 재귀 호출로 계산
			q = max(q, p[i] + Memoized-Cut-Rod-Aux(p, n - i, r))
	r[n] = q // 현재 값을 메모 배열에 저장
	return q
```

다음은 상향식 동적 프로그래밍 방식을 적용한 의사 코드입니다:
```pseudo
Bottom-Up-Cut-Rod(p, n)
	let r[0 .. n] be a new array // 메모 배열
	r[0] = 0 // 초기값 - 길이 0인 막대의 최적해는 0
	for j = 1 to n
		q = - ∞
		for i = 1 to j // 길이 j 보다 작은 경우에 대해서만 고려한다.
			q = max(q, p[i] + r[j - i])
		r[j] = q // 현재 값을 메모 배열에 저장
	return r[n]
```

위의 두 방식은 같은 점근적 실행 시간을 가집니다. `Bottom-Up-Cut-Rod()` 함수의 시간 복잡도는 `for` 문의 중첩되어있고 각 `for` 문은 최대 `n`번의 작업을 수행하기 때문에  $O(n^2)$입니다. `Memoized-Cut-Rod()` 함수의 시간 복잡도는 재귀적으로 구현되어 있어서 직관적으로 보이진 않지만 똑같이 $O(n^2)$입니다. 처음 보았던 백트래킹 방식처럼 재귀적으로 함수를 호출하지만, 하위 문제당 한 번만 계산하는 구현 방식 때문에 실제로는 `Bottom-Up-Rod()` 함수에서 처럼 이중 `for` 문을 실행하는 것과 같기 때문입니다.
###### 하위 문제 그래프
동적 프로그래밍 문제를 해결할 때는 연관된 하위 문제 집합을 이해하고 각각의 하위 문제가 어떻게 의존하고 있는지 알아야 합니다.

문제에 대한 *하위 문제 그래프*는 그 정보를 정확하게 포함합니다. 하위 문제 그래프는 방향 그래프이고, 각각의 노드는 기존 문제를 포함한 하위 문제를 의미합니다. 그리고 노드 $x$에서 노드 $y$로 가는 간선이 있다면 문제 $y$가 문제 $x$의 하위 문제이고 문제 $x$에서 문제 $y$를 호출함을 의미합니다. 하위 문제 그래프는 하향식 동적 프로그래밍 방식에 대한 재귀 트리의 축소 버전으로 생각할 수 있으며, 이것은 동일한 하위 문제에 대한 모든 노드를 단일 정점으로 통합하고 모든 간선을 부모 노드에서 자식 노드로 연결하는 것입니다.

동적 프로그래밍의 상향식 방법은 하위 문제 그래프의 노드를 특정한 순서로 고려하여, 주어진 하위 문제 $x$를 해결하기 전에 그와 인접한 하위 문제 $y$를 먼저 해결합니다. 22장의 용어를 사용하여 상향식 동적 프로그래밍 알고리즘에서 하위 문제 그래프의 정점을 '역 위상 정렬' 또는 하위 문제 그래프의 '위상 정렬' 순서로 고려합니다. 다시 말하면, 아래에 있는 하위 문제들이 해결되기 전에는 그 하위 문제들을 가리키는 하위 문제는 해결될 수 없습니다. 비슷하게, 하향식동적 프로그래밍 방식은 하위 문제 그래프를 '깊이 우선 탐색'하는 것으로 볼 수 있습니다.

하위 문제 그래프 $G = (V, E)$의 크기는 동적 프로그래밍 알고리즘의 실행 시간을 결정합니다. 하위 문제를 한 번만 해결하기 때문에 실행 시간은 각각의 하위 문제를 해결하는 데 필요한 실행 시간의 합입니다. 일반적으로 하위 문제를 해결하는데 걸리는 시간은 하위 문제 그래프에서 노드의 차수[^2]에 비례합니다. 그리고 하위 문제 그래프의 노드의 개수는 하위 문제의 개수입니다. 그러므로, 동적 프로그래밍 알고리즘의 실행시간은 노드 개수와 간선 개수의 선형식으로 표현됩니다.[^3]
###### 해 재구성하기
지금까지 알아본 막대 자르기 문제의 동적 프로그래밍 코드는 최대 수익을 반환하지만, 막대를 어떤 크기로 잘랐는지를 반환하지는 않습니다. 최대 수익을 계산하는 것 뿐만 아니라, 막대를 어떻게 잘랐는지도 기록할 수 있습니다. 

다음은 `Bottom-Up-Cut-Rod()` 함수의 확장된 버전입니다. 각 막대 크기 $j$에 대해, 최대 수익 $r_j$와 


- 백준 문제
	- [카드 구매하기](https://www.acmicpc.net/problem/11052)
	- [카드 구매하기 2](https://www.acmicpc.net/problem/16194)

#Algorithm #DP 

[^1]: 자를 수 있는 부분이 $n - 1$개 있고, 각 부분을 2 가지 경우-자를지 말지-로 독립적으로 계산할 수 있습니다.
[^2]: 여기서는 현재 노드에서 다른 노드로 향하는 간선의 개수를 의미합니다.
[^3]: 시간 복잡도는 $O(|V| + |E|)$입니다.